{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a class for visualizing the Decision Tree from the given datasets. \n",
    "\n",
    "    __init__(self, name='root', classifier = None):\n",
    "        Constructor for the class Tree. \n",
    "        The default name is 'root' if nothing else is given,\n",
    "        and a classifier is 'None' by default. \n",
    "        \n",
    "        Every object of class Tree has a name and a classifier. \n",
    "        They also have a list that holds on other object Tree,\n",
    "            (Empty if the object Tree has no children) \n",
    "        and a data variable which holds on the classifier data \n",
    "            (E.g cold --> yes {'yes': 2}, where {'yes': 2} is the data) \n",
    "     \n",
    "    __repr__(self):\n",
    "        Returns \n",
    "\n",
    "    set_data(self, data):\n",
    "        Set a data to an object \n",
    "         \n",
    "    set_name(self, name):\n",
    "        Set a name for an object (attribute) \n",
    "\n",
    "    set_classifier(self, classifier):\n",
    "        Set a classifier for an object (leaf)\n",
    "\n",
    "    add_child(self, tree):\n",
    "        Add a tree object (child) to another tree in a list\n",
    "\n",
    "    remove_child(self, child):\n",
    "        Remove a tree object of a tree \n",
    "\n",
    "    clear_children(self, tree):\n",
    "        Remove all children of a tree \n",
    "        \n",
    "    isLeaf(self):\n",
    "        Check if the tree object is a leaf (No children)\n",
    "\n",
    "    show(self, ind = 0):\n",
    "        Method for printing the tree. Parameter 'ind' is indent to make the tree\n",
    "        more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "\n",
    "    def __init__(self, name='root', classifier = None):\n",
    "        self.children = []\n",
    "        self.name = name\n",
    "        self.classifier = classifier\n",
    "        self.data = {}\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def set_classifier(self, classifier):\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.name)\n",
    "\n",
    "    def add_child(self, tree):\n",
    "        self.children.append(tree)\n",
    "\n",
    "    def remove_child(self, child):\n",
    "        self.children.remove(child)\n",
    "\n",
    "    def clear_children(self, tree):\n",
    "        self.children = []\n",
    "\n",
    "    def isLeaf(self):\n",
    "        return self.children.count(None) == len(self.children)\n",
    "\n",
    "    def show(self, ind = 0):\n",
    "        indent = ''\n",
    "        for i in range(ind):\n",
    "            indent = indent + ' | '\n",
    "\n",
    "        if self.isLeaf():\n",
    "            print(indent, self.name, '-->', self.classifier, self.data)\n",
    "        else:\n",
    "            print(indent, self.name, 'is a parent with children:',self.children , self.data)\n",
    "\n",
    "            for child in self.children:\n",
    "                child.show(ind + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function learns a decision tree classifier from data X and y. \n",
    "The learn()-function takes in four parameters:\n",
    "    X:\n",
    "        The dataset which includes all the data labels\n",
    "\n",
    "    y: \n",
    "        Data which holds the classification \n",
    "        (not included in data X) \n",
    "        \n",
    "    impurity_measure: \n",
    "        Chooses a formula to measure the information gain. \n",
    "        Can choose between 'entropy' or 'gini'.\n",
    "        By default, the learning function will use 'entropy' as \n",
    "        an impurity measure for information gain.\n",
    "       \n",
    "    pruning:\n",
    "        This parameter is used to prune the decision tree created by\n",
    "        the learning function. Pruning will remove branches that \n",
    "        causes overfitting. \n",
    "        Can choose 'True' or 'False' to prune the tree or not.\n",
    "        By default, the pruning is set to 'False'. \n",
    "        \n",
    "    return Tree:\n",
    "        The function returns a decision tree with children and leaves. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Tree import Tree\n",
    "import operator\n",
    "\n",
    "def learn(X, y, impurity_measure = 'entropy', pruning = False):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "\n",
    "    (X,y) = update_data(X, y)\n",
    "    print('Impurity_measure:', impurity_measure)\n",
    "\n",
    "    #X = X_train, y = y_train\n",
    "    #if pruning:\n",
    "    #    tree = makeTree(X_train, y_train, impurity_measure)\n",
    "\n",
    "    return makeTree(X, y, impurity_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Updates the datasets. If a question mark '?' appears in a row in the data X, remove the whole row. Also remove the corresponding classifier in data y. \n",
    "    X:\n",
    "        Dataset X (attributes)\n",
    "    y:\n",
    "        Dataset y (classifier)\n",
    "\n",
    "    return (newX, newy):\n",
    "        Returns a new X and y without rows containing a question mark '?'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(X, y):\n",
    "    newX = []\n",
    "    newy = []\n",
    "    for row in range(len(y)):\n",
    "        if '?' not in X[row]:\n",
    "            newX.append(X[row])\n",
    "            newy.append(y[row])\n",
    "    return (newX, newy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function is used to predict class label of some new data point x.\n",
    "Takes in two parameters:\n",
    "    x:\n",
    "        Some data point in form of a list which is used to predict \n",
    "        the classifier.\n",
    "       \n",
    "    tree:\n",
    "        The decision tree where the predict is used on. \n",
    "    \n",
    "    return tree.classifier:\n",
    "        The function will return a classifier that matches the \n",
    "        data point x. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, tree):\n",
    "    if tree.isLeaf():\n",
    "        return tree.classifier\n",
    "    else:\n",
    "        for child in tree.children:\n",
    "            child.name = child.name.strip()\n",
    "            if child.name in x:\n",
    "                list(x).remove(child.name)\n",
    "                return predict(x, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function makeTree() creates the decision tree with data X and y with an impurity measure which is used to find the best feature to split the decision tree. \n",
    "The function takes three parameters: \n",
    "    X:\n",
    "        The dataset X to build the decision tree, also known as \n",
    "        attributes. Usually the parent of a classifier or another \n",
    "        attribute. \n",
    "    y:\n",
    "        Data which holds the classifier. This is the leaves in the \n",
    "        tree.\n",
    "        \n",
    "    impurity_measure:\n",
    "        Used to measure information gain with a given formula. \n",
    "        \n",
    "calculateInformationGain() returns a index where the best feature occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTree(X, y, impurity_measure):\n",
    "    if is_pure(y):\n",
    "        return Tree(classifier = y[0])\n",
    "\n",
    "    elif len(np.transpose(X)) == 0: # no features left\n",
    "        mcl = most_common_label(y)\n",
    "        return Tree(classifier = mcl)\n",
    "\n",
    "    else:\n",
    "        tree = Tree()\n",
    "        index = calculateInformationGain(X, y, impurity_measure)\n",
    "\n",
    "        for attribute_value, [splitted_X, splitted_y] in split(X, y, index).items():\n",
    "            child = makeTree(splitted_X, splitted_y, impurity_measure)\n",
    "            child.set_name(attribute_value)\n",
    "            child.set_data(countLetters(splitted_y))\n",
    "            tree.add_child(child)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to split after finding the best index in data X. \n",
    "    X:\n",
    "        Data X (may also be a new X, after getting splitted) \n",
    "    \n",
    "    y:\n",
    "        Data y (may be new y, after getting splitted)\n",
    "\n",
    "    index:\n",
    "        Index after finding the best feature (index of a column in X) \n",
    "\n",
    "    return dict:\n",
    "        Returns a dictionary with attribute and a corresponding classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, index):\n",
    "    dict = {}\n",
    "    for i in range(len(y)):\n",
    "        if X[i][index] in dict:\n",
    "            dict[X[i][index]][0].append(X[i][:index] + X[i][index+1:])\n",
    "            dict[X[i][index]][1].append(y[i])\n",
    "        else:\n",
    "            dict[X[i][index]] = [[X[i][:index] + X[i][index+1:]], [y[i]]]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function is_pure() checks if a dataset only contains the value\n",
    "    y: \n",
    "        A dataset \n",
    "    \n",
    "    return len(set(y)) == 1:\n",
    "        Returns either True or False depending on the data\n",
    "\n",
    "Function most_common_label() see which attribute is the most common in the dataset\n",
    "    y: \n",
    "        A dataset\n",
    "\n",
    "    return sortedClassifier[0][0]:\n",
    "        Returns the most common label (attribute) in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pure(y):\n",
    "    return len(set(y)) == 1\n",
    "\n",
    "def most_common_label(y):\n",
    "    dict = {}\n",
    "    for classifier in y:\n",
    "        if classifier not in dict.keys():\n",
    "            dict[classifier] = 0\n",
    "        dict[classifier] += 1\n",
    "    sortedClassifier = sorted(dict.items(), key = operator.itemgetter(1), reverse=False)\n",
    "    return sortedClassifier[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calculateInformationGain() calculates the information gain with datasets and a given type of measure.\n",
    "    X: \n",
    "        Dataset X\n",
    "    \n",
    "    y:\n",
    "        Dataset y \n",
    "        \n",
    "    impurity_measure:\n",
    "        Choice of impurity measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateInformationGain(X, y, impurity_measure):\n",
    "    ig_list = []\n",
    "    #A dictionary with function mapped to the keys\n",
    "    impurity_func = {'entropy': calc_entropy, 'gini': calc_gini}\n",
    "    #measure is a function that matches the impurity_measure \n",
    "    measure = impurity_func.get(impurity_measure)\n",
    "\n",
    "    for row in np.transpose(X):\n",
    "        #Put the probabilities of the values in a list \n",
    "        probabilities = [counter/len(y) for counter in countLetters(y).values()]\n",
    "        \n",
    "        #Here we calculate the probability \n",
    "        information_measure = measure(probabilities)\n",
    "        ig = information_measure\n",
    "        for attribute_value, occurrence_dict in zip_xy_class(row, y).items():\n",
    "            s = sum(occurrence_dict.values())\n",
    "            X_probabilities = [counter/s for counter in occurrence_dict.values()]\n",
    "            attribute_measure = measure(X_probabilities)\n",
    "            weight = s/len(y)\n",
    "\n",
    "            gain -= weight * attribute_measure\n",
    "\n",
    "        ig_list.append(gain)\n",
    "\n",
    "    index = np.argmax(ig_list)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calc_entropy() takes a list of probabilities, calculates the entropy of each value and sum them together.\n",
    "    listprob:\n",
    "        A list of probabilities\n",
    "        \n",
    "    return entropy:\n",
    "        Returns the entropy of the calculated values\n",
    "  \n",
    "calc_gini() also takes a list of probabilities, but calculates the gini instead\n",
    "    return gini:\n",
    "        Returns the entropy of the calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(listprob):\n",
    "    entropy = 0\n",
    "    for prob in listprob:\n",
    "        if prob != 0:\n",
    "            entropy += -prob * np.log2(prob)\n",
    "    return entropy\n",
    "\n",
    "def calc_gini(listprob):\n",
    "    gini = 0\n",
    "    for prob in listprob:\n",
    "        if prob != 0:\n",
    "            gini += prob * (1 - prob)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Helper function that counts occurrence of an element in a list. \n",
    "The dictionary holds on an element and a value that is a counter of occurrenes of that element.\n",
    "Functions takes an array:\n",
    "    array:\n",
    "        An array with elements\n",
    "    \n",
    "    return dict:\n",
    "        Returns a dictionary with a key (element) and a value (occurrence of an element in the list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countLetters(array):\n",
    "    dict = {}\n",
    "    for i in array:\n",
    "        if i in dict:\n",
    "            dict[i] += 1\n",
    "        else:\n",
    "            dict[i] = 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Helper function that connects the data X and y together. Also count how many occurrences of a classifier an attribute has. \n",
    "E.g {' sunny': {'no': 1, 'yes': 1}, ' cloudy': {'yes': 2}}, where attribute sunny has two classification and occurrences of the classification for the attribute. \n",
    "This functions takes: \n",
    "    X:\n",
    "        Dataset X, attributes\n",
    "    y:\n",
    "        Dataset y, classifications\n",
    "        \n",
    "    return dict:\n",
    "        Returns a dictionary for an attribute in X with the corresponding \n",
    "        classifiers and the number of occurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_xy_class(X, y):\n",
    "    dict = {}\n",
    "    for attribute, classifier in list(zip(X, y)):\n",
    "        if attribute in dict:\n",
    "            if classifier in dict[attribute]:\n",
    "                dict[attribute][classifier] += 1\n",
    "            else:\n",
    "                dict[attribute][classifier] = 1\n",
    "        else:\n",
    "            dict[attribute] = {classifier : 1 }\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " ____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impurity_measure: entropy\n",
      " root is a parent with children: [n, c, f, l, a, p, m] {}\n",
      " |  n is a parent with children: [k, n, w, r] {'e': 1825, 'p': 59}\n",
      " |  |  k --> e {'e': 865}\n",
      " |  |  n --> e {'e': 896}\n",
      " |  |  w is a parent with children: [p, y, n, c, g, w] {'e': 64, 'p': 12}\n",
      " |  |  |  p --> e {'e': 4}\n",
      " |  |  |  y --> p {'p': 7}\n",
      " |  |  |  n --> e {'e': 31}\n",
      " |  |  |  c --> e {'e': 24}\n",
      " |  |  |  g --> e {'e': 5}\n",
      " |  |  |  w --> p {'p': 5}\n",
      " |  |  r --> p {'p': 47}\n",
      " |  c --> p {'p': 128}\n",
      " |  f --> p {'p': 1053}\n",
      " |  l --> e {'e': 253}\n",
      " |  a --> e {'e': 264}\n",
      " |  p --> p {'p': 162}\n",
      " |  m --> p {'p': 26}\n",
      "{True: 1373, False: 1310}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from ID3 import learn, makeTree, predict\n",
    "from Tree import Tree\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "with open('agaricus-lepiota.data') as csv_file:\n",
    "        reader = csv.reader(open(\"agaricus-lepiota.data\", \"rb\"), delimiter=\",\")\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            y.append(row[0])\n",
    "            X.append(row[1:])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "#For my ID3 implementation:\n",
    "myTree = learn(X_train, y_train, 'entropy', True)\n",
    "myTree.show()\n",
    "\n",
    "dict = {}\n",
    "for row in range(len(X_test)):\n",
    "    pred = predict(X[row], myTree)\n",
    "    result = pred == y_test[row]\n",
    "    if result not in dict:\n",
    "        dict[result] = 1\n",
    "\n",
    "    if (result):\n",
    "        dict[result] += 1\n",
    "    else:\n",
    "        dict[result] += 1\n",
    "print(dict)\n",
    "\n",
    "#print(prune(X, y, tree))\n",
    "\n",
    "#5. Implementation comparision\n",
    "X_T = []\n",
    "le = LabelEncoder()\n",
    "for i in range(len(np.transpose(X_train))):\n",
    "    X_T.append(le.fit_transform(np.transpose(X_train)[i]))\n",
    "X_train = np.transpose(X_T)\n",
    "\n",
    "X_T = []\n",
    "for i in range(len(np.transpose(X_train))):\n",
    "    X_T.append(le.fit_transform(np.transpose(X_test)[i]))\n",
    "X_test = np.transpose(X_T)\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_predict = dtc.predict(X_test)\n",
    "\n",
    "dict = {}\n",
    "for i in dtc_predict:\n",
    "    result = dtc_predict[i] == y_test[i]\n",
    "    if result not in dict:\n",
    "        dict[result] = 1\n",
    "\n",
    "    if (result):\n",
    "        dict[result] += 1\n",
    "    else:\n",
    "        dict[result] += 1\n",
    "\n",
    "print(dict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the ID3 algorithm from scratch\n",
    "The implementation is above\n",
    "\n",
    "2. Gini Index\n",
    "The learn() has entropy as a default impurity measure, but can be switched to gini with giving 'gini' as parameter\n",
    "\n",
    "3. Pruning\n",
    "Did not implement the pruning because of time remaining. \n",
    "\n",
    "4. Classify edible and poisonous mushrooms\n",
    "Entropy and gini gives the same result of splitting even with random state. \n",
    "\n",
    "5. Implementation comparison:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "Splitted the data into training data and test data with test_size 0.33\n",
    "\n",
    "For my implementation, my prediction got {False: 1740, True: 943} while the sklearn got {True: 2682}. \n",
    "\n",
    "My predict() is not completely correct, because I had problems with removing an attribute from the data I want to predict. Did not find another solution for this because of the time remaining. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
